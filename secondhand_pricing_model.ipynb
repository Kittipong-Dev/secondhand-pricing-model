{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyUJ13MKaYDrTnwrNBjBJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kittipong-Dev/secondhand-pricing-model/blob/main/secondhand_pricing_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "292ExdGrQlH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcc4204-55d5-4bb3-92ae-0f2c73b54c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-23 14:50:07--  https://github.com/NextGen-AI-Camp/curriculum-2025/releases/download/Workshop-Week2-Dataset/dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/974978898/68dc38c4-3c9a-4094-9b09-7d5a94633577?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250623%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250623T145007Z&X-Amz-Expires=1800&X-Amz-Signature=03c2bd949b019878b4a3fef5244b790a1acfa762634f3c6cedb9e41c74fcb39f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ddataset.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-23 14:50:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/974978898/68dc38c4-3c9a-4094-9b09-7d5a94633577?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250623%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250623T145007Z&X-Amz-Expires=1800&X-Amz-Signature=03c2bd949b019878b4a3fef5244b790a1acfa762634f3c6cedb9e41c74fcb39f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ddataset.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453930721 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip          15%[==>                 ] 210.01M  95.8MB/s               ^C\n",
            "Archive:  dataset.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of dataset.zip or\n",
            "        dataset.zip.zip, and cannot find dataset.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "# download file\n",
        "!wget https://github.com/NextGen-AI-Camp/curriculum-2025/releases/download/Workshop-Week2-Dataset/dataset.zip\n",
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1ubtmPeIRIVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import all dependencies\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from PIL import Image\n",
        "\n",
        "import librosa\n",
        "import IPython.display as display\n",
        ""
      ],
      "metadata": {
        "id": "DX1ZUd-CRQSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try using cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "XWBrQ-NST7M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsM1WQKgbsMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6J9XTD8b2pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out)) + self.shortcut(x)\n",
        "        return F.relu(out)\n",
        ""
      ],
      "metadata": {
        "id": "iszQH4UXb39B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SecondhandAudioEvaluatingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.labels = [\"smell\", \"pilling\", \"condition\"]\n",
        "        self.out_dims = [2, 5, 5]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1_block1 = BasicBlock(64, 64, stride=1)\n",
        "        self.layer1_block2 = BasicBlock(64, 64, stride=1)\n",
        "        self.layer2_block1 = BasicBlock(64, 128, stride=2)\n",
        "        self.layer2_block2 = BasicBlock(128, 128, stride=1)\n",
        "        self.layer3_block1 = BasicBlock(128, 256, stride=2)\n",
        "        self.layer3_block2 = BasicBlock(256, 256, stride=1)\n",
        "        self.layer4_block1 = BasicBlock(256, 512, stride=2)\n",
        "        self.layer4_block2 = BasicBlock(512, 512, stride=1)\n",
        "\n",
        "        # Explicitly name heads for each task\n",
        "        self.head_smell = nn.Linear(512, 2)\n",
        "        self.head_pilling = nn.Linear(512, 5)\n",
        "        self.head_condition = nn.Linear(512, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.layer1_block1(x); x = self.layer1_block2(x)\n",
        "        x = self.layer2_block1(x); x = self.layer2_block2(x)\n",
        "        x = self.layer3_block1(x); x = self.layer3_block2(x)\n",
        "        x = self.layer4_block1(x); x = self.layer4_block2(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)  # [B, 512]\n",
        "\n",
        "        # Return dictionary without for loop\n",
        "        return {\n",
        "            \"smell\": self.head_smell(x),\n",
        "            \"pilling\": self.head_pilling(x),\n",
        "            \"condition\": self.head_condition(x)\n",
        "        }"
      ],
      "metadata": {
        "id": "mHRFAm34m5Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SecondhandImageEvaluatingModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SecondhandImageEvaluatingModel, self).__init__()\n",
        "    self.labels = [\"type\", \"color\"]\n",
        "    self.out_dims = [2, 11]  # type has 2 classes, color has 11\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.layer1_block1 = BasicBlock(64, 64, stride=1)\n",
        "    self.layer1_block2 = BasicBlock(64, 64, stride=1)\n",
        "    self.layer2_block1 = BasicBlock(64, 128, stride=2)\n",
        "    self.layer2_block2 = BasicBlock(128, 128, stride=1)\n",
        "    self.layer3_block1 = BasicBlock(128, 256, stride=2)\n",
        "    self.layer3_block2 = BasicBlock(256, 256, stride=1)\n",
        "    self.layer4_block1 = BasicBlock(256, 512, stride=2)\n",
        "    self.layer4_block2 = BasicBlock(512, 512, stride=1)\n",
        "    self.type_out = nn.Linear(512 * BasicBlock.expansion, type_num_classes)\n",
        "    self.color_out = nn.Linear(512 * BasicBlock.expansion, color_num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.maxpool(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "    out = self.layer1_block1(out) #64\n",
        "    out = self.layer1_block2(out)\n",
        "\n",
        "    out = self.layer2_block1(out) #128\n",
        "    out = self.layer2_block2(out)\n",
        "\n",
        "    out = self.layer3_block1(out) #256\n",
        "    out = self.layer3_block2(out)\n",
        "\n",
        "    out = self.layer4_block1(out) #512\n",
        "    out = self.layer4_block2(out)\n",
        "\n",
        "    out = nn.AdaptiveAvgPool2d((1, 1))(out) # [32, 512, 7, 7] --> [32, 512, 1, 1]\n",
        "    out = out.view(out.size(0), -1) # [32, 512]\n",
        "\n",
        "    type_out, color_out = self.type_out(out), self.color_out(out)\n",
        "    return type_out, color_out"
      ],
      "metadata": {
        "id": "sr9NWX02nGMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SecondhandEvaluatingModel(nn.Module):\n",
        "  def __init__(self, modelA=SecondhandAudioEvaluatingModel(), modelB=SecondhandImageEvaluatingModel(), task_keysA=[\"smell\", \"pilling\", \"condition\"], task_keysB=[\"type\", \"color\"]):\n",
        "    super().__init__()\n",
        "    self.modelA = modelA\n",
        "    self.modelB = modelB\n",
        "    self.task_keysA = task_keysA\n",
        "    self.task_keysB = task_keysB\n",
        "    self.out_dims = [modelA.out_dims[modelA.labels.index(k)] for k in task_keysA] + \\\n",
        "                    [modelB.out_dims[modelB.labels.index(k)] for k in task_keysB]\n",
        "\n",
        "  def forward(self, xA, xB):\n",
        "    outA = self.modelA(xA)\n",
        "    outB = self.modelB(xB)\n",
        "    out = {}\n",
        "    for k in self.task_keysA:\n",
        "        out[k] = outA[k]\n",
        "    for k in self.task_keysB:\n",
        "        out[k] = outB[k]\n",
        "    return out"
      ],
      "metadata": {
        "id": "jGLLbPsQRh6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoLabelImageDataset(Dataset):\n",
        "    def __init__(self, df, image_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.df.iloc[idx]['image_name']\n",
        "        path = os.path.join(self.image_folder, fname)\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, fname"
      ],
      "metadata": {
        "id": "7Z9yq7kmb5HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.6554, 0.6678, 0.6761],\n",
        "                         std=[0.1793, 0.1804, 0.1822])\n",
        "])"
      ],
      "metadata": {
        "id": "o3XQ1oKThCra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "PAp1XpkHhEUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NoLabelImageDataset(df, image_folder, transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "fAFyAMZvhI12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"\"\n",
        "output_path = \"\"\n",
        "pth_path = \"\""
      ],
      "metadata": {
        "id": "F6qzZaTmaROu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SecondhandEvaluatingModel()\n",
        "model.load_state_dict(torch.load(pth_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "idx_to = {\n",
        "    \"type\": ['bottom', 'top'],\n",
        "    \"color\": ['Black', 'Blue', 'Brown', 'Gray', 'Green', 'Orange', 'Pink', 'Purple', 'Red', 'White', 'Yellow'],\n",
        "    \"smell\": [\"FALSE\",  \"TRUE\"],\n",
        "    \"pilling\": [str(i) for i in range(1, 6)],\n",
        "    \"condition\": [str(i) for i in range(1, 6)]\n",
        "}\n",
        "labels = [\"type\", \"color\", \"smell\", \"pilling\", \"condition\"]\n",
        "updates = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, filenames in tqdm(loader):\n",
        "    images = images.to(device)\n",
        "    out = model(, images)\n",
        "\n",
        "    batch_preds = {\n",
        "      label: out[label].argmax(dim=1).cpu().numpy()\n",
        "      for label in labels\n",
        "    }\n",
        "\n",
        "    for i, fname in enumerate(filenames):\n",
        "      record = {\"image_name\": fname}\n",
        "      for label in labels:\n",
        "        class_idx = batch_preds[label][i]\n",
        "        record[label] = idx_to[label][class_idx]\n",
        "      updates.append(record)\n",
        "\n",
        "updates_df = pd.DataFrame(updates).set_index(\"image_name\")\n",
        "\n",
        "df = df.set_index(\"image_name\")\n",
        "for col in labels:\n",
        "    df[col] = updates_df[col]\n",
        "\n",
        "df = df.reset_index()\n",
        "\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Saved csv to {output_path}\")"
      ],
      "metadata": {
        "id": "j5Ap9D8fRVzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vp0VNSDnWJu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}